{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "D5hy4YHk8nZR",
        "3qizN_etrgz5",
        "I2iCsrIkyXQC",
        "Y9yoeyAuw3M-"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction California Housing Prices Dataset ðŸ“š**"
      ],
      "metadata": {
        "id": "D5hy4YHk8nZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Median house prices for California districts derived from the 1990 census."
      ],
      "metadata": {
        "id": "OEW4G0LU84wZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About Dataset**"
      ],
      "metadata": {
        "id": "kC82lOMu9OKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The California Housing Prices dataset, commonly referred to as the \"California Housing\" dataset, is a popular dataset used in machine learning and data analysis. It is often featured on platforms like Kaggle for educational and practice purposes. Here is a brief introduction to the dataset:"
      ],
      "metadata": {
        "id": "cLifH2qK9Dpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Source**"
      ],
      "metadata": {
        "id": "HLv8fBuu-cYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is based on data collected during the 1990 California census. It is often used as a benchmark dataset for regression problems, particularly in predicting housing prices."
      ],
      "metadata": {
        "id": "jrN0921C-eTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Features**"
      ],
      "metadata": {
        "id": "9McNwOX-_FGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset includes various features that can be used to predict the median house value for California districts. Some of the key features include:"
      ],
      "metadata": {
        "id": "dE9XOBnZ_bO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **longitude**: A measure of how far west a house is; a higher value is farther west\n",
        "* **latitude**: A measure of how far north a house is; a higher value is farther north\n",
        "* **housingMedianAge**: Median age of a house within a block; a lower number is a newer building\n",
        "* **totalRooms**: Total number of rooms within a block\n",
        "* **totalBedrooms**: Total number of bedrooms within a block\n",
        "* **population**: Total number of people residing within a block\n",
        "* **households**: Total number of households, a group of people residing within a home unit, for a block\n",
        "* **medianIncome**: Median income for households within a block of houses (measured in tens of thousands of US Dollars)\n",
        "* **medianHouseValue**: Median house value for households within a block (measured in US Dollars)\n",
        "* **oceanProximity**: Location of the house w.r.t ocean/sea"
      ],
      "metadata": {
        "id": "JfTrVPai_dlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target Variable**"
      ],
      "metadata": {
        "id": "8Kgku61JANeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The target variable is Median House Value, which represents the median house value for California districts (in units of 100,000)."
      ],
      "metadata": {
        "id": "u3arvCkLAcY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link dataset**: https://www.kaggle.com/datasets/camnugent/california-housing-prices"
      ],
      "metadata": {
        "id": "-UPdBmL1Ib-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preprocessing**"
      ],
      "metadata": {
        "id": "3qizN_etrgz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read dataset from github**"
      ],
      "metadata": {
        "id": "OPUmilJNruVe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU89FT62qgRm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/honganhdinh2002/California-Housing-Prices-Kaggle.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TeXxz_5FsAG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/California-Housing-Prices-Kaggle/california_housing_price.csv')"
      ],
      "metadata": {
        "id": "IkGSuQAFr5QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset.copy()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Keme7S5BsXrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each row represents one district. There are 10 attributes: longitude, latitude, housing_median_age, total_rooms, total_bedrooms, population, household, median_income, median_house_value, and ocean_proximity.\n",
        "\n",
        "The info() method is useful to get a quick description of the data, in particular the total number of rows, each attribute's type, and the number of nonull values."
      ],
      "metadata": {
        "id": "uJf_qrlFNTxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "2s7dUMfKsfPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shape of data**"
      ],
      "metadata": {
        "id": "HvOL5jHVw35m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nRow, nCol = df.shape\n",
        "print(\"Shape of dataset {}\".format(df.shape))\n",
        "print(f\"Rows: {nRow} \\nColumns: {nCol}\")"
      ],
      "metadata": {
        "id": "dsdY6Yllw5f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode categorical values**"
      ],
      "metadata": {
        "id": "gmTvpBc4tadr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 10 features: 9 numberic and 1 category. The category should be converted to the numberic"
      ],
      "metadata": {
        "id": "emnzNo56AoN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as ex\n",
        "\n",
        "ex.pie(df ,names='ocean_proximity', title='Proportion of Locations of the house w.r.t ocean/sea')"
      ],
      "metadata": {
        "id": "szkm3d24syAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"ocean_proximity\"].value_counts()"
      ],
      "metadata": {
        "id": "p91FgIjftFxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "ocean_proximity_le = LabelEncoder()"
      ],
      "metadata": {
        "id": "CX4kFBTpta_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ocean_proximity'] = ocean_proximity_le.fit_transform(df['ocean_proximity'])"
      ],
      "metadata": {
        "id": "Fxraj_u_tewh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ID\\tRepresentation value\")\n",
        "for i in range(len(ocean_proximity_le.classes_)):\n",
        "    print(f\"{i}\\t\\t{ocean_proximity_le.classes_[i]}\")"
      ],
      "metadata": {
        "id": "jyH5PyPovOiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fig=plt.figure(figsize=(17, 4))\n",
        "plt.subplot(132)\n",
        "sns.boxplot( x=df[\"ocean_proximity\"], y=df[\"median_house_value\"], palette=\"Blues\").set_title('Median House Value Boxplot by Ocean Proximity')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ygEujKWpcy2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Describe the dataset**"
      ],
      "metadata": {
        "id": "E3jz25urIIPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "IAwtkqKGwRWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The average house price is above 200,000 USD\n",
        "* The highest house price is 500,000 USD\n",
        "* The lowest house price is 15,000 USD"
      ],
      "metadata": {
        "id": "xG27dunfJZap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handle missing data**"
      ],
      "metadata": {
        "id": "Wm6RvAC_w9TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isna().sum())\n",
        "df.isna().sum().plot(kind='bar')"
      ],
      "metadata": {
        "id": "KYsHcAOHw781"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "print(df.isna().sum())"
      ],
      "metadata": {
        "id": "VX0y7I_0xAqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check and remove duplicated data**"
      ],
      "metadata": {
        "id": "CzL_1fKuxLXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().value_counts()"
      ],
      "metadata": {
        "id": "zlfVZRSCxL_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_duplicates =  df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
        "df.duplicated().value_counts()"
      ],
      "metadata": {
        "id": "pCK5QFSLxUo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handle outlier values**"
      ],
      "metadata": {
        "id": "RGsECSZ0xYYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(18,8))\n",
        "sns.boxplot(data=df)"
      ],
      "metadata": {
        "id": "sh-Mp0xJxY7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling median house value outliners**"
      ],
      "metadata": {
        "id": "Hf4WXUk0FlKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = df[(df['median_house_value'] <= 470000)]\n",
        "df0.shape[0]"
      ],
      "metadata": {
        "id": "HSJcObOMFqsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling total rooms outliers**"
      ],
      "metadata": {
        "id": "MpW2SxZVxppr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax =plt.subplots(1,2, figsize=(12,8))\n",
        "sns.boxplot(data=df, y='total_rooms', ax=ax[0], color='#7209b7')\n",
        "sns.scatterplot(data=df,x = 'median_house_value', s = 100, y='total_rooms', ax=ax[1])"
      ],
      "metadata": {
        "id": "rJu6alxbxtY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df0[(df0['total_rooms'] <= 23000)]\n",
        "df1.shape[0]"
      ],
      "metadata": {
        "id": "rX2h1rJCxwox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*225 rows were removed about 1% to handle total rooms outliers*"
      ],
      "metadata": {
        "id": "PpfTOOB_x0f1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling total bedrooms outliers**"
      ],
      "metadata": {
        "id": "XgBfgQKsx470"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax =plt.subplots(1,2, figsize=(12,8))\n",
        "sns.boxplot(data=df1, y='total_bedrooms', ax=ax[0], color='#7209b7')\n",
        "sns.scatterplot(data=df1,x = 'median_house_value', s = 100, y='total_bedrooms', ax=ax[1])"
      ],
      "metadata": {
        "id": "X1CRNip6x1MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1[(df1['total_bedrooms'] < 3000)]\n",
        "df2.shape"
      ],
      "metadata": {
        "id": "sFNth9aox9nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*49 rows were removed about 0.24% to handle total bedrooms outliers*"
      ],
      "metadata": {
        "id": "i2E4gH1Kx-6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling population outliers**"
      ],
      "metadata": {
        "id": "M8a24IuTyA5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax =plt.subplots(1,2, figsize=(12,8))\n",
        "sns.boxplot(data=df2, y='population', ax=ax[0], color='#7209b7')\n",
        "sns.scatterplot(data=df2,x = 'median_house_value', s = 100, y='population', ax=ax[1])"
      ],
      "metadata": {
        "id": "R_e8OJn6yCol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df2[(df2['population'] < 7500)]\n",
        "df3.shape[0]"
      ],
      "metadata": {
        "id": "E4q3guyKyFSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*37 rows were removed about 0.18% to handle population outliers*"
      ],
      "metadata": {
        "id": "V6hu5sUByHkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling households outliers**"
      ],
      "metadata": {
        "id": "29e-VvityITA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax =plt.subplots(1,2, figsize=(12,8))\n",
        "sns.boxplot(data=df3, y='households', ax=ax[0], color='#7209b7')\n",
        "sns.scatterplot(data=df3,x = 'median_house_value', s = 100, y='households', ax=ax[1])"
      ],
      "metadata": {
        "id": "gYWXU2FAyH33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df3[(df3['households'] < 2300)]\n",
        "df4.shape[0]"
      ],
      "metadata": {
        "id": "80lzoX7SyLGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*47 rows were removed about 0.23% to handle households outliers*"
      ],
      "metadata": {
        "id": "3KQQpPs7yNx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling median income outliers**"
      ],
      "metadata": {
        "id": "rITtOoG3yOOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax =plt.subplots(1,2, figsize=(12,8))\n",
        "sns.boxplot(data=df4, y='median_income', ax=ax[0], color='#7209b7')\n",
        "sns.scatterplot(data=df4,x = 'median_house_value', s = 100, y='median_income', ax=ax[1])"
      ],
      "metadata": {
        "id": "ilYGWAcmyQXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = df4[(df4['median_income'] < 11)]\n",
        "df5.shape[0]"
      ],
      "metadata": {
        "id": "2rAqtLs0yTBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*156 rows were removed about 0.76% to handle median income outliers*"
      ],
      "metadata": {
        "id": "LF8PEN6MyWrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "514 rows were removed to handle outliers about 2.5%"
      ],
      "metadata": {
        "id": "t3HH9RMOyZ4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize data**"
      ],
      "metadata": {
        "id": "I2iCsrIkyXQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "        s=df5[\"population\"]/100, label=\"population\", figsize=(15,8),\n",
        "        c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),colorbar=True,\n",
        "    )\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D7YOigJnyc4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation**"
      ],
      "metadata": {
        "id": "N34HW2KfyiyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = df5[['longitude', 'latitude' ,'housing_median_age', 'total_rooms',\n",
        "       'total_bedrooms','population', 'households', 'median_income', 'ocean_proximity', 'median_house_value']]"
      ],
      "metadata": {
        "id": "Vr6NWJ6cyjKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,8))\n",
        "sns.heatmap(df5.corr() , annot = True , cmap = \"YlGnBu\")"
      ],
      "metadata": {
        "id": "bvVdBopXymhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* median income has 68% relation with median house value.\n",
        "* total rooms has 16% relation with median house value.\n",
        "* latitude has 14% relation with median house value.\n",
        "* housing median age has 11% relation with median house value.\n",
        "* longitude has 92% relation with longitude.\n",
        "* longitude has 29% relation with ocean proximity.\n",
        "* latitude has 20% relation with ocean proximity.\n",
        "* median income has 24% relation with total rooms.\n",
        "* median house age has averag 32% relation with total rooms, total bedrooms,  population and households.\n",
        "* total rooms, total bedrooms, population and households have average 92% relation with eachother.\n",
        "\n"
      ],
      "metadata": {
        "id": "_iPvcnkNzBVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target variable median_house_value is very mildly correlated to all but one feature here: median_income, so one might outline this as an important feature."
      ],
      "metadata": {
        "id": "q-T1wlaCEcdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = df5.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "K2EGCDedNok0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Median house value distribution**\n"
      ],
      "metadata": {
        "id": "UHZCam7ozCy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram\n",
        "\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(131)\n",
        "\n",
        "(sns.distplot(df5[\"housing_median_age\"], bins = \"fd\", norm_hist = True, kde = False, color = \"skyblue\", hist_kws = dict(alpha = 1))\n",
        "    .set(xlabel = \"Housing Median Age\", ylabel = \"Density\", title = \"Median House Age Histogram\"));\n",
        "\n",
        "plt.subplot(132)\n",
        "\n",
        "(sns.distplot(df5[\"total_rooms\"], bins = \"fd\", norm_hist = True, kde = False, color = \"skyblue\", hist_kws = dict(alpha = 1))\n",
        "    .set(xlabel = \"Total Rooms\", ylabel = \"Density\", title = \"Total Rooms Histogram\"));\n",
        "\n",
        "plt.subplot(133)\n",
        "\n",
        "(sns.distplot(df5[\"total_bedrooms\"], bins = \"fd\", norm_hist = True, kde = False, color = \"skyblue\", hist_kws = dict(alpha = 1))\n",
        "    .set(xlabel = \"Total Bedrooms\", ylabel = \"Density\", title = \"Total Bedrooms Histogram\"));\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Boxplot\n",
        "\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(131)\n",
        "sns.boxplot(y=df5[\"housing_median_age\"], color=\"skyblue\").set_title('Median House Age Boxplot')\n",
        "\n",
        "plt.subplot(132)\n",
        "sns.boxplot(y=df5[\"total_rooms\"], color=\"skyblue\").set_title('Total Rooms Boxplot')\n",
        "\n",
        "plt.subplot(133)\n",
        "sns.boxplot(y=df5[\"total_bedrooms\"], color=\"skyblue\").set_title('Total Bedrooms Boxplot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Histogram\n",
        "\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(131)\n",
        "\n",
        "(sns.distplot(df5[\"population\"], bins = \"fd\", norm_hist = True, kde = False, color = \"skyblue\", hist_kws = dict(alpha = 1))\n",
        "    .set(xlabel = \"Population\", ylabel = \"Density\", title = \"Population Histogram\"));\n",
        "\n",
        "plt.subplot(132)\n",
        "\n",
        "(sns.distplot(df5[\"households\"], bins = \"fd\", norm_hist = True, kde = False, color = \"skyblue\", hist_kws = dict(alpha = 1))\n",
        "    .set(xlabel = \"Households\", ylabel = \"Density\", title = \"Households Histogram\"));\n",
        "\n",
        "plt.subplot(133)\n",
        "\n",
        "(sns.distplot(df5[\"median_income\"], bins = \"fd\", norm_hist = True, kde = False, color = \"skyblue\", hist_kws = dict(alpha = 1))\n",
        "    .set(xlabel = \"Median Income\", ylabel = \"Density\", title = \"Median Income Histogram\"));\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Boxplot\n",
        "\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(131)\n",
        "sns.boxplot(y=df5[\"population\"], color=\"skyblue\").set_title('Population Boxplot')\n",
        "\n",
        "plt.subplot(132)\n",
        "sns.boxplot(y=df5[\"households\"], color=\"skyblue\").set_title('Households Boxplot')\n",
        "\n",
        "plt.subplot(133)\n",
        "sns.boxplot(y=df5[\"median_income\"], color=\"skyblue\").set_title('Median Income Boxplot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4aDoi0_azFC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split data**"
      ],
      "metadata": {
        "id": "ymmnlb0lzIQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5.columns"
      ],
      "metadata": {
        "id": "8WdWeXlTzpV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = df5[['longitude', 'latitude', 'housing_median_age',\n",
        "       'total_bedrooms', 'population', 'households', 'median_income',\n",
        "       'ocean_proximity', 'median_house_value']]"
      ],
      "metadata": {
        "id": "YR3tSNyMzrlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final.tail(2)"
      ],
      "metadata": {
        "id": "gsnhoL3Az2GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = final.drop(['median_house_value'] , axis = 1).values\n",
        "y = final['median_house_value'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 42)"
      ],
      "metadata": {
        "id": "Ltp72reNz4OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaling**"
      ],
      "metadata": {
        "id": "44vRdIJKG4dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scale = StandardScaler()"
      ],
      "metadata": {
        "id": "1Pu6KDZ60BqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train=scale.fit_transform(X_train)\n",
        "# X_test=scale.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "80rODWDV0FC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train.shape, y_train.shape"
      ],
      "metadata": {
        "id": "-FtSvzkv0GYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression**"
      ],
      "metadata": {
        "id": "HSLAuHYY0Ijx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression models are useful for prediction and to explain variation in the response variable. In this case, we will focus on prediction. So we will fit a predictive model to an observed data set of values of the response and explanatory variables.\n",
        "\n",
        "To run the linear model we will use a class from Scikit-learn called **Linear Regression()** this class has a function called **fit()** , which will train our data."
      ],
      "metadata": {
        "id": "WsTgA59TweFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error , mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "K8FDUs-90KJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr.predict(X_test)"
      ],
      "metadata": {
        "id": "6-u7kVJo0L9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see above, that the variable regressor_linear is a Linear Regression model trained from the variables X_train and y_train. To train the model means that we are looking for the line that better fits the training data, to do so we will use the **predict()** function."
      ],
      "metadata": {
        "id": "Tpril_WqwoIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn import metrics\n",
        "\n",
        "mae_linear = np.round(metrics.mean_absolute_error(y_test, y_pred_lr))\n",
        "mse_linear = np.round(metrics.mean_squared_error(y_test, y_pred_lr))\n",
        "rmse_linear = np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_lr)))\n",
        "\n",
        "\n",
        "print('Mean Absolute Error:', mae_linear, 2)\n",
        "print('Mean Squared Error:', mse_linear, 2)\n",
        "print('Root Mean Squared Error:', rmse_linear, 2)"
      ],
      "metadata": {
        "id": "a4lzuiGi0URU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_frame = pd.DataFrame({\"Y_test\": y_test , \"Y_pred\" : y_pred_lr})\n",
        "lr_frame.head(10)"
      ],
      "metadata": {
        "id": "M_rFkXBq0ObJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(lr_frame[:50])\n",
        "plt.legend([\"Actual\" , \"Predicted\"])"
      ],
      "metadata": {
        "id": "MpM7t1li0R4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# residual plot\n",
        "plt.figure(figsize=(12,7))\n",
        "(sns.distplot((y_test-y_pred_lr), bins = \"fd\", norm_hist = True, kde = False, color = \"skyblue\", hist_kws = dict(alpha = 1))\n",
        "    .set(xlabel = \"(y_test-y_pred)\", ylabel = \"Density\"\n",
        "    , title = \"Regression Tree Residual Plot\"));"
      ],
      "metadata": {
        "id": "I4taOwGM0ejH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression typically has less hyperparameters that need to be tuned compared to more complex models."
      ],
      "metadata": {
        "id": "huK1kEiZWvHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest**"
      ],
      "metadata": {
        "id": "aKPdP11d0g4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest is an evolution of bagging. The Random Forest model provide an **improvement over bagged trees** by way of a small tweak that **decorrelates the trees**.\n",
        "\n",
        "As in bagging, we build a number of decision trees on bootstrapped training samples. But when building these decision trees, each time a split in a tree is considered, a **random sample of m predictors is chosen as split candidates from the full set of p predictors**. The idea behind this process is to decorrelate the trees, for example: Suppose that there is one very strong predictor in the data set, along with a number of other moderately strong predictors. Then in the collection of bagged trees, most or all of the trees will use this strong predictor in the top split. Consequently, all of the bagged trees will look quite similar to each other. Hence the predictions from the bagged trees will be highly correlated.\n",
        "\n",
        "In Random Forest p is the full set of predictors and m is the predictors taken at each split. So, **the main difference between bagging and random forests is the choice of predictor subset size m**. For instance, if a random forest is built using m = p, then this amounts simply to bagging."
      ],
      "metadata": {
        "id": "GMpzJjuFwtaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "regressor_rf = RandomForestRegressor(random_state=42)\n",
        "regressor_rf.fit(X_train, y_train)\n",
        "y_pred_forest = regressor_rf.predict(X_test)"
      ],
      "metadata": {
        "id": "RuceNqlv0i4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae_forest = np.round(metrics.mean_absolute_error(y_test, y_pred_forest))\n",
        "mse_forest = np.round(metrics.mean_squared_error(y_test, y_pred_forest))\n",
        "rmse_forest = np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_forest)))\n",
        "\n",
        "\n",
        "print('Mean Absolute Error:', mae_forest, 2)\n",
        "print('Mean Squared Error:', mse_forest, 2)\n",
        "print('Root Mean Squared Erro:', rmse_forest, 2)"
      ],
      "metadata": {
        "id": "MUnRYKcJ0wqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tunning hyperparameters Random Forest Regression**"
      ],
      "metadata": {
        "id": "4qgvEixd0z6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_"
      ],
      "metadata": {
        "id": "DLVKgRsxhfW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dá»± Ä‘oÃ¡n trÃªn táº­p kiá»ƒm thá»­\n",
        "y_pred_forest_cv = grid_search.predict(X_test)\n",
        "\n",
        "# ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t\n",
        "mse = mean_squared_error(y_test, y_pred_forest_cv)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared: {rmse}\")"
      ],
      "metadata": {
        "id": "ZuJtJL10h4Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Error on Test Set: 1897876002.331699\n",
        "Root Mean Squared Error on Test Set: 43564.618698339356"
      ],
      "metadata": {
        "id": "RdQiKAd7FGrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because after tunning, the rmse, mse and mae values â€‹â€‹do not change, so we can take either model."
      ],
      "metadata": {
        "id": "rmRlHBS6XOO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor_rf_frame_cv = pd.DataFrame({\"Y_test\": y_test , \"Y_pred\" : y_pred_forest_cv})\n",
        "regressor_rf_frame_cv.head(10)"
      ],
      "metadata": {
        "id": "AA7wSTfm06V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(regressor_rf_frame_cv[:50])\n",
        "plt.legend([\"Actual\" , \"Predicted\"])"
      ],
      "metadata": {
        "id": "rEqQAeyS07kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression Tree**"
      ],
      "metadata": {
        "id": "QjkAB5wQ1AFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees methods involve stratifying or segmenting the predictor space into a number of simple regions. Decision Trees are **simple and useful for interpretation**, however they are typically **not competitive in terms of prediction accuracy**.\n",
        "\n",
        "Decision trees can be applied to both **regression and classification problems**. At this task, we are going to use **Regression Trees**\n",
        "\n",
        "**Advantages of Decision Trees**:\n",
        "\n",
        "1. Trees are very easy to explain to people. In fact, they are even easier to explain than linear regression!\n",
        "2. Some people believe that decision trees more closely mirror human decision-making than do the regression and classification approaches seen in previous chapters.\n",
        "3. Trees can be displayed graphically, and are easily interpreted even by a non-expert (especially if they are small).\n",
        "4. Trees can easily handle qualitative predictors without the need to create dummy variables,\n",
        "\n",
        "**Disadvantages of Decision Trees**:\n",
        "\n",
        "1. Unfortunately, trees generally do not have the same level of predictive accuracy as some of the other regression and classification approaches seen in this book.\n",
        "2. Additionally, trees can be very non-robust. In other words, a small change in the data can cause a large change in the final estimated tree (high variance)\n",
        "\n",
        "However, by aggregating many decision trees the predictive performance of trees can be substantially improved. We will evaluate these models in the next cells."
      ],
      "metadata": {
        "id": "4PvPi2IGwyH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "regressor_tree = DecisionTreeRegressor(random_state = 42)\n",
        "regressor_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_tree = regressor_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "Gh0bshrf1DNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae_tree = np.round(metrics.mean_absolute_error(y_test, y_pred_tree))\n",
        "mse_tree = np.round(metrics.mean_squared_error(y_test, y_pred_tree))\n",
        "rmse_tree = np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_tree)))\n",
        "\n",
        "\n",
        "print('Mean Absolute Error:', mae_tree, 2)\n",
        "print('Mean Squared Error:', mse_tree, 2)\n",
        "print('Root Mean Squared Erro:', rmse_tree, 2)"
      ],
      "metadata": {
        "id": "FT8QiUCO1Lo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tunning hyperparameters Regression Tree**"
      ],
      "metadata": {
        "id": "tLcO3iC21Neo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [None, 5, 10, 15, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10, 15, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 8, 12]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(regressor_tree, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "t_II683n1O3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_regressor_tree = grid_search.best_estimator_\n",
        "y_pred_tree_cv = best_regressor_tree.predict(X_test)"
      ],
      "metadata": {
        "id": "cFgpWxPC1RK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae_tree_cv = np.round(metrics.mean_absolute_error(y_test, y_pred_tree_cv))\n",
        "mse_tree_cv = np.round(metrics.mean_squared_error(y_test, y_pred_tree_cv))\n",
        "rmse_tree_cv = np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_tree_cv)))\n",
        "\n",
        "\n",
        "print('Mean Absolute Error:', mae_tree_cv, 2)\n",
        "print('Mean Squared Error:', mse_tree_cv, 2)\n",
        "print('Root Mean Squared Erro:', rmse_tree_cv, 2)"
      ],
      "metadata": {
        "id": "3pBy-7Um1VWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because after tunning, the rmse, mse and mae values â€‹â€‹change for the better, so we will take the tunning model"
      ],
      "metadata": {
        "id": "9mFuW-_IYPG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor_tree_frame_cv = pd.DataFrame({\"Y_test\": y_test, \"Y_pred\": y_pred_tree_cv})\n",
        "regressor_tree_frame_cv.head(10)"
      ],
      "metadata": {
        "id": "erUpyiWN1Sen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(regressor_tree_frame_cv[:50])\n",
        "plt.legend([\"Actual\" , \"Predicted\"])"
      ],
      "metadata": {
        "id": "pJI89eTE1UOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# residual plot\n",
        "plt.figure(figsize=(12,7))\n",
        "(sns.distplot((y_test-y_pred_tree_cv), bins = \"fd\", norm_hist = True, kde = False, color = \"skyblue\", hist_kws = dict(alpha = 1))\n",
        "    .set(xlabel = \"(y_test-y_pred)\", ylabel = \"Density\", title = \"RF Residual Plot\"));"
      ],
      "metadata": {
        "id": "D5xxdHho1Wp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison Regression Tree**"
      ],
      "metadata": {
        "id": "uEvteGNb1YPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['Regression Tree' , 'Regression Tree CV']\n",
        "data = [\n",
        "    [mae_tree, mse_tree, rmse_tree],\n",
        "    [mae_tree_cv, mse_tree_cv, rmse_tree_cv]\n",
        "]\n",
        "\n",
        "cols = ['mae' , 'mse', 'rmse']\n",
        "\n",
        "df = pd.DataFrame(data=data, index=models, columns=cols)\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "_L4wiMFz1Zma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient Boosting Regression**"
      ],
      "metadata": {
        "id": "Y9yoeyAuw3M-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting Regression** is a powerful machine learning algorithm used for regression problems. It belongs to the category of Ensemble Learning, where a series of weak models (weak learners) are combined to create a strong model (strong learner)."
      ],
      "metadata": {
        "id": "ROv1-Bm2akpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Táº¡o mÃ´ hÃ¬nh Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor()\n",
        "\n",
        "# Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p huáº¥n luyá»‡n\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Dá»± Ä‘oÃ¡n trÃªn táº­p kiá»ƒm tra\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "# ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t sá»­ dá»¥ng Mean Squared Error\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
        "\n",
        "# TÃ­nh Root Mean Squared Error\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "\n",
        "print(\"Mean Squared Error on Test Set:\", mse_gb)\n",
        "print(\"Root Mean Squared Error on Test Set:\", rmse_gb)"
      ],
      "metadata": {
        "id": "60VKV8Abw6JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tunning hyperparameters  gradient boostring regression**"
      ],
      "metadata": {
        "id": "cc6hTjCMU87Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Äá»‹nh nghÄ©a lÆ°á»›i hyperparameters báº¡n muá»‘n thá»­ nghiá»‡m\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "# Sá»­ dá»¥ng GridSearchCV Ä‘á»ƒ tÃ¬m kiáº¿m hyperparameters tá»‘t nháº¥t\n",
        "grid_search = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# In ra hyperparameters tá»‘t nháº¥t\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# DÃ¹ng hyperparameters tá»‘t nháº¥t Ä‘á»ƒ táº¡o mÃ´ hÃ¬nh\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "# Dá»± Ä‘oÃ¡n trÃªn táº­p kiá»ƒm tra vÃ  Ä‘Ã¡nh giÃ¡ láº¡i hiá»‡u suáº¥t\n",
        "y_pred_gb_best = best_gb_model.predict(X_test)\n",
        "mse_gb_best = mean_squared_error(y_test, y_pred_gb_best)\n",
        "print(\"Mean Squared Error on Test Set (Best Model):\", mse_gb_best)\n",
        "\n",
        "rmse_gb_best = np.sqrt(mse_gb_best)\n",
        "print(\"Root Mean Squared Error on Test Set (Best Model):\", rmse_gb_best)\n"
      ],
      "metadata": {
        "id": "-Pn7Ha4LxT7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Error on Test Set (Best Model): 1710899232.3084118\n",
        "\n",
        "Root Mean Squared Error on Test Set (Best Model): 41363.01768861179"
      ],
      "metadata": {
        "id": "4YZw280REcxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb_frame_cv = pd.DataFrame({\"Y_test\": y_test, \"Y_pred\": y_pred_gb})\n",
        "gb_frame_cv.head(10)"
      ],
      "metadata": {
        "id": "KGOSVWrmDVgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae_gb_cv = np.round(metrics.mean_absolute_error(y_test, y_pred_gb_best))\n",
        "mse_gb_cv = np.round(metrics.mean_squared_error(y_test, y_pred_gb_best))\n",
        "rmse_gb_cv = np.round(np.sqrt(metrics.mean_squared_error(y_test, y_pred_gb_best)))\n",
        "\n",
        "\n",
        "print('Mean Absolute Error:', mae_gb_cv, 2)\n",
        "print('Mean Squared Error:', mse_gb_cv, 2)\n",
        "print('Root Mean Squared Erro:', rmse_gb_cv, 2)"
      ],
      "metadata": {
        "id": "Ai6Qb8fbDj79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(gb_frame_cv[:50])\n",
        "plt.legend([\"Actual\" , \"Predicted\"])"
      ],
      "metadata": {
        "id": "z9CEhjWZDxaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation models**"
      ],
      "metadata": {
        "id": "nYLMQY2n667i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabulate"
      ],
      "metadata": {
        "id": "UQWGeW4bf8FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "# Assuming y_test, y_pred_lr, y_pred_forest, y_pred_tree are defined for the entire test dataset\n",
        "\n",
        "# Create a DataFrame to store the evaluation metrics\n",
        "results_df = pd.DataFrame(columns=['Model', 'MAE', 'MSE', 'RMSE'])\n",
        "\n",
        "# Calculate evaluation metrics for LR\n",
        "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mse_lr)\n",
        "results_df = results_df.append({'Model': 'Linear Regression', 'MAE': f'{mae_lr:.2f}', 'MSE': '{:.2f}'.format(mse_lr), 'RMSE': f'{rmse_lr:.2f}'}, ignore_index=True)\n",
        "\n",
        "# Calculate evaluation metrics for Random Forest\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_forest)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_forest)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "results_df = results_df.append({'Model': 'Random Forest', 'MAE': f'{mae_rf:.2f}', 'MSE': '{:.2f}'.format(mse_rf), 'RMSE': f'{rmse_rf:.2f}'}, ignore_index=True)\n",
        "\n",
        "# Calculate evaluation metrics for Decision Tree\n",
        "mae_tree = mean_absolute_error(y_test, y_pred_tree_cv)\n",
        "mse_tree = mean_squared_error(y_test, y_pred_tree_cv)\n",
        "rmse_tree = np.sqrt(mse_tree)\n",
        "results_df = results_df.append({'Model': 'Regression Tree', 'MAE': f'{mae_tree:.2f}', 'MSE': '{:.2f}'.format(mse_tree), 'RMSE': f'{rmse_tree:.2f}'}, ignore_index=True)\n",
        "\n",
        "# Calculate evaluation metrics for Gradient Boosting\n",
        "mae_gb = mean_absolute_error(y_test, y_pred_gb_best)\n",
        "mse_gb = mean_squared_error(y_test, y_pred_gb_best)\n",
        "rmse_gb = np.sqrt(mse_gb)\n",
        "results_df = results_df.append({'Model': 'Gradient Boosting', 'MAE': f'{mae_gb:.2f}', 'MSE': '{:.2f}'.format(mse_gb), 'RMSE': f'{rmse_gb:.2f}'}, ignore_index=True)\n",
        "\n",
        "# Display the table\n",
        "print(tabulate(results_df, headers='keys', tablefmt='fancy_grid'))\n"
      ],
      "metadata": {
        "id": "ELUjEXn4kGHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define labels and data for plotting\n",
        "models = ['Linear Regression', 'Random Forest', 'Decision Tree', 'Gradient Boosting']\n",
        "mae_values = [mae_lr, mae_rf, mae_tree, mae_gb]\n",
        "mse_values = [mse_lr, mse_rf, mse_tree, mse_gb]\n",
        "rmse_values = [rmse_lr, rmse_rf, rmse_tree, rmse_gb]\n",
        "\n",
        "# Set up colors\n",
        "colors = ['steelblue', 'forestgreen', 'darkorange', 'slategray']\n",
        "\n",
        "# Set up bar width\n",
        "bar_width = 0.2\n",
        "\n",
        "# Set up positions for bars on x-axis\n",
        "r1 = np.arange(len(models))\n",
        "r2 = [x + bar_width for x in r1]\n",
        "r3 = [x + bar_width for x in r2]\n",
        "\n",
        "# Plotting MAE\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(r1, mae_values, color=colors, width=bar_width, edgecolor='grey', label='MAE')\n",
        "plt.xlabel('Models', fontweight='bold')\n",
        "plt.xticks([r + bar_width for r in range(len(models))], models)\n",
        "plt.title('Mean Absolute Error (MAE) Comparison')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting MSE\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(r2, mse_values, color=colors, width=bar_width, edgecolor='grey', label='MSE')\n",
        "plt.xlabel('Models', fontweight='bold')\n",
        "plt.xticks([r + bar_width for r in range(len(models))], models)\n",
        "plt.title('Mean Squared Error (MSE) Comparison')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting RMSE\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(r3, rmse_values, color=colors, width=bar_width, edgecolor='grey', label='RMSE')\n",
        "plt.xlabel('Models', fontweight='bold')\n",
        "plt.xticks([r + bar_width for r in range(len(models))], models)\n",
        "plt.title('Root Mean Squared Error (RMSE) Comparison')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EjWUN9VJoXC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results: which is the best model?**"
      ],
      "metadata": {
        "id": "UPnKH-EAyfqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen from the table below, **gradient boostring regression** resulted to be the best model for this dataset because of:\n",
        "* lowest root mean squared error\n",
        "\n",
        "\n",
        "With the average house price fluctuates around more than 200K USD. **Gradient Boostring** gives the average value of the deviation between the predicted value and the actual value of 40K (about ~ 18- 19%). It sounds good.\n",
        "\n",
        "After gradient boostring, **RF** is ~ 43K (about ~ 20%), **LR** and **DTR** is more than 25%.\n"
      ],
      "metadata": {
        "id": "8Xj_1fJBtTZO"
      }
    }
  ]
}